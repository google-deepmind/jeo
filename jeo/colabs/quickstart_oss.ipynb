{
  "cells": [
    {
      "metadata": {
        "id": "AlQ3nm8GUiwo"
      },
      "cell_type": "markdown",
      "source": [
        "# Jeo Quickstart\n",
        "\n",
        "This notebook provides a hands-on introduction to the `jeo` library, a framework for training deep learning models for geospatial remote sensing and Earth Observation using JAX and Flax. It is designed to work with large-scale datasets, often created using Google Earth Engine (GEE) via the accompanying `geeflow` library.\n",
        "\n",
        "\n",
        "In this quickstart, you will walk through the fundamental steps of the **training flow**. To keep things simple and fast, we will use the standard CIFAR-10 image dataset instead of a large geospatial one. You will learn how to:\n",
        "1.  Load a configuration file.\n",
        "2.  Instantiate a training dataset using a `tf.data` input pipeline.\n",
        "3.  Define a model and initialize its parameters.\n",
        "4.  Set up an optimizer and a learning rate schedule.\n",
        "5.  Execute a single training step to see how the model's weights are updated.\n",
        "Finally, we will demonstrate how to run the end-to-end training process using the main `train.main()` function."
      ]
    },
    {
      "metadata": {
        "id": "AUVcdb9YRMfM"
      },
      "cell_type": "code",
      "source": [
        "import functools\n",
        "import importlib\n",
        "\n",
        "import logging\n",
        "import sys\n",
        "from absl import logging as absl_logging\n",
        "\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import flax\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import tree\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "print(\"tf.executing_eagerly(): \", tf.executing_eagerly())\n",
        "print(\"JAX devices:\\n  \" + \"\\n  \".join([repr(d) for d in jax.devices()]))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "0MMrSh9ERMhM"
      },
      "cell_type": "code",
      "source": [
        "# Make absl.logging use the standard Python logging setup.\n",
        "absl_logging.use_python_logging(quiet=True)\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "for h in logger.handlers[:]:\n",
        "    logger.removeHandler(h)\n",
        "handler = logging.StreamHandler(sys.stderr)\n",
        "formatter = logging.Formatter(\n",
        "    '%(levelname)s: %(asctime)s %(filename)s:%(lineno)d] %(message)s',\n",
        "    datefmt='%Y-%m-%d %H:%M:%S'\n",
        ")\n",
        "handler.setFormatter(formatter)\n",
        "logger.addHandler(handler)\n",
        "absl_logging.info(\"ABSL logging is now configured for this notebook.\")\n",
        "logging.info(\"Standard logging is also configured.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "8PbgaFpmRMjS"
      },
      "cell_type": "code",
      "source": [
        "\"\"\"# Following the trainer flow\n",
        "\n",
        "This section presents an example workflow of the trainer, and we'll perform the following steps:\n",
        "\n",
        "1. Load a config `jeo/configs/tests/tiny_bit.py`. It is a simple classification using BiT model on Cifar-10 dataset.\n",
        "2. Instantiate the train dataset.\n",
        "3. Inspect the train dataset.\n",
        "4. Instantiate the model.\n",
        "5. Load model parameters.\n",
        "6. Perform a training step.\n",
        "7. Run evaluation.\n",
        "\n",
        "Note: You can as well follow the `jeo/train.py` module, which does these steps.\n",
        "\"\"\"\n",
        "# Get config\n",
        "\n",
        "# Has tree_info for quick inspection of nested structures.\n",
        "from jeo.tools import inspect\n",
        "from jeo.configs.tests import tiny_bit\n",
        "\n",
        "tiny_bit = importlib.reload(tiny_bit)\n",
        "\n",
        "config = tiny_bit.get_config()\n",
        "\n",
        "# We can adjust it even more if needed.\n",
        "config.batch_size = 256\n",
        "config.val_steps = 2  # Don't perform more than 2 steps at evaluation.\n",
        "\n",
        "# Show config.\n",
        "config"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "mPic6PBoRMlC"
      },
      "cell_type": "code",
      "source": [
        "# Let's quickly look into the specification of preprocessing:\n",
        "print(config.pp_train)\n",
        "\n",
        "# This string describes ops to be applied on the input data within the tf.data.Dataset input pipeline.\n",
        "print(\"Input pipeline ops are applied in sequential order:\")\n",
        "for x in config.pp_train.split(\"|\"):\n",
        "  print(f\"  {x}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "PK7rYfYOUYt6"
      },
      "cell_type": "markdown",
      "source": [
        "## Train dataset"
      ]
    },
    {
      "metadata": {
        "id": "-MTr81OHRMnU"
      },
      "cell_type": "code",
      "source": [
        "# Let's specify batch sizes and set the random seed.\n",
        "\n",
        "rng = jax.random.PRNGKey(0)\n",
        "rng, rng_loop = jax.random.split(rng, 2)\n",
        "\n",
        "batch_size_train = config.batch_size\n",
        "batch_size_eval = config.get(\"batch_size_eval\", default=batch_size_train)\n",
        "local_batch_size_train = batch_size_train // jax.process_count()\n",
        "local_batch_size_eval = batch_size_eval // jax.process_count()\n",
        "\n",
        "# Get the dataset (using TFDS for Cifar-10)\n",
        "from jeo import input_pipeline\n",
        "from jeo.pp import pp_builder  # Preprocessing fn builder.\n",
        "\n",
        "# fillin() function is used to replace xm-related tokens in paths.\n",
        "# Since we don't use XM, we can keep as identity.\n",
        "fillin = lambda x: x\n",
        "\n",
        "train_ds, num_train_examples = input_pipeline.get_data(\n",
        "    train=True,\n",
        "    dataset=config.dataset,\n",
        "    split=config.train_split,\n",
        "    data_dir=fillin(config.get(\"dataset_dir\")),\n",
        "    dataset_module=config.get(\"dataset_module\"),\n",
        "    **config.get(\"dataset_kwargs\", default={}),\n",
        "    batch_size=local_batch_size_train,\n",
        "    preprocess_fn=pp_builder.get_preprocess_fn(config.pp_train),\n",
        "    shuffle_buffer_size=config.get(\"shuffle_buffer_size\"),\n",
        "    prefetch=config.get(\"prefetch_to_host\", 2),\n",
        "    cache_raw=False)\n",
        "\n",
        "# Start prefetching already.\n",
        "train_iter = input_pipeline.start_input_pipeline(train_ds, config.get(\"prefetch_to_device\", 1))\n",
        "\n",
        "# Let's look into the spec of the data (single batch):\n",
        "train_ds.element_spec"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "tKESCSpmRMpn"
      },
      "cell_type": "code",
      "source": [
        "# Get some examples.\n",
        "\n",
        "# Get 8 batches:\n",
        "ex = [jax.tree.map(np.array, next(train_iter)) for _ in range(8)]\n",
        "\n",
        "# Show content shapes:\n",
        "inspect.tree_info(ex[0])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "IGci1wxERMrv"
      },
      "cell_type": "code",
      "source": [
        "# Note: each example has 2 batch dimensions right now: (num_devices,\n",
        "# batch_size_per_device).\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(13, 6))\n",
        "for i in range(8):\n",
        "  plt.subplot(2, 4, 1+i)\n",
        "  # Since our images are scaled into the range [-1, 1], we need to rescale into [0, 1] for visualization\n",
        "  plt.imshow(ex[i]['image'][0, 0] /2.0 +0.5)  # only first image of batch\n",
        "  # Labels are already one-hot encoded (as specified in the pp_train string).\n",
        "  plt.title(str(ex[i]['labels'][0, 0]))\n",
        "\n",
        "# get number of images, steps per epoch, total steps\n",
        "ntrain_img = input_pipeline.get_num_examples(\n",
        "      config.dataset, config.train_split,\n",
        "      data_dir=config.get(\"dataset_dir\"))\n",
        "steps_per_epoch = ntrain_img / batch_size_train\n",
        "\n",
        "if config.get(\"total_epochs\"):\n",
        "  total_steps = int(config.total_epochs * steps_per_epoch)\n",
        "else:\n",
        "  total_steps = config.total_steps\n",
        "\n",
        "ntrain_img, steps_per_epoch, total_steps"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "8bo2RhgTUVf3"
      },
      "cell_type": "markdown",
      "source": [
        "## Model"
      ]
    },
    {
      "metadata": {
        "id": "HgX490M1TL25"
      },
      "cell_type": "code",
      "source": [
        "# Let's get the model\n",
        "from jeo import train_utils\n",
        "\n",
        "\n",
        "print(\"Get module based on the one specified in config: \", config.model_name)\n",
        "model_mod = train_utils.import_module(config.model_name, \"models\")\n",
        "\n",
        "# Instantiate model with config overwrites in config.model\n",
        "model = model_mod.Model(**config.model)\n",
        "\n",
        "# Let's have a look at the model - that's a very simple ResNet with just a few args.\n",
        "model"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "dwReBo7JTL5Y"
      },
      "cell_type": "code",
      "source": [
        "# Let's initialize the model.\n",
        "\n",
        "@functools.partial(jax.jit, backend=\"cpu\")\n",
        "def init(rng):\n",
        "  image_size = tuple(train_ds.element_spec[\"image\"].shape[1:])\n",
        "  x = jnp.zeros((local_batch_size_train,) + image_size, jnp.float32)\n",
        "  variables = model.init(rng, x, train=True)\n",
        "  model_state, params = flax.core.pop(variables, \"params\")\n",
        "  params = flax.core.unfreeze(params)\n",
        "  # Set bias in the head to a low value, such that loss is small initially.\n",
        "  if \"init_head_bias\" in config:\n",
        "    params[\"head\"][\"bias\"] = jnp.full_like(params[\"head\"][\"bias\"],\n",
        "                                            config[\"init_head_bias\"])\n",
        "  return params, model_state\n",
        "\n",
        "rng, rng_init, rng_dropout, rng_mask = jax.random.split(rng, 4)\n",
        "rng_init = {\"params\": rng_init, \"dropout\": rng_dropout, \"mask\": rng_mask,\n",
        "            \"masking\": rng_mask}\n",
        "params_cpu, state_cpu = init(rng_init)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "qOERdfNnTL7c"
      },
      "cell_type": "code",
      "source": [
        "# Let's inspect the params - model weights.\n",
        "inspect.tree_info(params_cpu)\n",
        "\n",
        "# This particular model doesn't have state params (as eg. used for BatchNorm)\n",
        "print(state_cpu)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "Es4HHntdUR1h"
      },
      "cell_type": "markdown",
      "source": [
        "## Optimizer"
      ]
    },
    {
      "metadata": {
        "id": "4yusf_oMTL9y"
      },
      "cell_type": "code",
      "source": [
        "# Get optimizer\n",
        "from jeo.tools import bv_optax\n",
        "\n",
        "tx, sched_fns = bv_optax.make(config, params_cpu, sched_kw=dict(\n",
        "    global_batch_size=batch_size_train,\n",
        "    total_steps=total_steps,\n",
        "    steps_per_epoch=steps_per_epoch))\n",
        "\n",
        "# We jit this, such that the arrays are created on the CPU, not device[0].\n",
        "opt_cpu = jax.jit(tx.init, backend=\"cpu\")(params_cpu)\n",
        "sched_fns_cpu = [jax.jit(sched_fn, backend=\"cpu\") for sched_fn in sched_fns]\n",
        "\n",
        "# Let's visualize the (relative!) learning rate schedule - the scaling with base_lr happens later.\n",
        "plt.plot([sched_fns_cpu[0](x) for x in range(total_steps)])\n",
        "\n",
        "# This particular shape is given by the spec of warmup_epochs/steps (eg. 1ep) and decay type (cosine)."
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "5C_seoZjUOx1"
      },
      "cell_type": "markdown",
      "source": [
        "## Train step"
      ]
    },
    {
      "metadata": {
        "id": "A4HBDD8JTL_3"
      },
      "cell_type": "code",
      "source": [
        "# Let's define an update train step:\n",
        "import jeo.tasks.classification\n",
        "from jeo.tasks import task_builder\n",
        "import optax\n",
        "\n",
        "# Get the problem task.\n",
        "task = task_builder.from_config(config)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "FAUvhpreTMCV"
      },
      "cell_type": "code",
      "source": [
        "@functools.partial(jax.pmap, axis_name=\"batch\", donate_argnums=(0, 1))\n",
        "def update_fn(params, state, opt, rng, batch):\n",
        "  \"\"\"Update step.\"\"\"\n",
        "  measurements = {}\n",
        "  # Get device-specific loss rng.\n",
        "  rng, rng_model = jax.random.split(rng, 2)\n",
        "  rng_model_local = jax.random.fold_in(rng_model, jax.lax.axis_index(\"batch\"))\n",
        "\n",
        "  def loss_fn(params, state, batch):\n",
        "    model_inputs = task.model_inputs(batch)\n",
        "    model_outputs, mutated_state = model.apply(\n",
        "        {\"params\": flax.core.freeze(params), **state}, *model_inputs,\n",
        "        train=True, mutable=list(state.keys()),\n",
        "        rngs={\"dropout\": rng_model_local, \"mask\": rng_model_local,\n",
        "              \"masking\": rng_model_local})\n",
        "    loss, aux = task.get_loss_and_aux(model_outputs, batch, train=True)\n",
        "    aux[\"state\"] = mutated_state\n",
        "    return loss, aux\n",
        "\n",
        "  (l, aux), grads = jax.value_and_grad(loss_fn, has_aux=True)(params, state,\n",
        "                                                              batch)\n",
        "  l, aux, grads = jax.lax.pmean((l, aux, grads), axis_name=\"batch\")\n",
        "  updates, opt = tx.update(grads, opt, params)\n",
        "  params = optax.apply_updates(params, updates)\n",
        "  state = aux.pop(\"state\")\n",
        "\n",
        "  gs = jax.tree.leaves(bv_optax.replace_frozen(config.schedule, grads, 0.))\n",
        "  measurements[\"l2_grads\"] = jnp.sqrt(sum([jnp.vdot(g, g) for g in gs]))\n",
        "  ps = jax.tree.leaves(params)\n",
        "  measurements[\"l2_params\"] = jnp.sqrt(sum([jnp.vdot(p, p) for p in ps]))\n",
        "  us = jax.tree.leaves(updates)\n",
        "  measurements[\"l2_updates\"] = jnp.sqrt(sum([jnp.vdot(u, u) for u in us]))\n",
        "  st = jax.tree.leaves(state)\n",
        "  measurements[\"l2_state\"] = jnp.sqrt(sum([jnp.vdot(s, s) for s in st]))\n",
        "  for k, v in aux.items():\n",
        "    measurements[f\"train_{k}\"] = v\n",
        "\n",
        "  return params, state, opt, rng, l, measurements"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "2PRJyY7gTMEW"
      },
      "cell_type": "code",
      "source": [
        "# Before doing any training, we need to replicate the parameters across devices:\n",
        "import flax.jax_utils as flax_utils\n",
        "\n",
        "params_repl = flax_utils.replicate(params_cpu)\n",
        "state_repl = flax_utils.replicate(state_cpu)\n",
        "opt_repl = flax_utils.replicate(opt_cpu)\n",
        "rngs_loop = flax_utils.replicate(rng_loop)\n",
        "\n",
        "# Get next train batch\n",
        "\n",
        "train_batch = next(train_iter)\n",
        "\n",
        "# Do a training step\n",
        "\n",
        "out = update_fn(params_repl, state_repl, opt_repl, rngs_loop, train_batch)\n",
        "\n",
        "# The train-step update_fn returns:\n",
        "#   new updated params, potentially updated states, updated optimizer states, a new rng seed, loss, and measurement metrics.\n",
        "\n",
        "params, state, opt, rng, l, measurements = out\n",
        "\n",
        "# You can inspect all of them eg. with inspect.tree_info(params)\n",
        "\n",
        "# Let's have a look at computed measurements:\n",
        "measurements"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "7EdlZIwtTMGn"
      },
      "cell_type": "code",
      "source": [
        "# Note that the values within the arrays are the same, just replicated across\n",
        "# devices. So, a natural thing to do is to just take the first element (or use\n",
        "# unreplicate).\n",
        "\n",
        "flax_utils.unreplicate(measurements)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "eB3SGWkTUFna"
      },
      "cell_type": "markdown",
      "source": [
        "# End-to-End run with train.main()"
      ]
    },
    {
      "metadata": {
        "id": "DOHJ7rL-TMI6"
      },
      "cell_type": "code",
      "source": [
        "from jeo import evaluators\n",
        "from jeo import train\n",
        "from jeo.configs.tests import tiny_bit\n",
        "\n",
        "config = tiny_bit.get_config()\n",
        "# Update config to run in a colab (in dependence of used accelerators).\n",
        "config.xprof = False\n",
        "config.batch_size = 64\n",
        "config.total_epochs = 2  # 2 epochs is enough for demonstration.\n",
        "if \"fewshot\" in config.evals:\n",
        "  del config.evals.fewshot  # fewshot eval is currently not available.\n",
        "\n",
        "from absl import flags\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "FLAGS.config = config\n",
        "FLAGS.cleanup = False\n",
        "FLAGS.workdir = \"/tmp/jeo_test/run1\"\n",
        "\n",
        "train.main(None)"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
